
import asyncio
import os
import sys
import uuid
import logging
import base64
import glob
from datetime import datetime
from unittest.mock import patch

# Standard ADK/A2A Evaluation imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))

from dotenv import load_dotenv
from a2a.types import Message, Role, Part, TextPart, MessageSendParams, FilePart, FileWithBytes
from a2a.server.agent_execution import RequestContext
from a2a.server.events import EventQueue

from app.agent import root_agent 
from app.app_utils.executor.careflow_executor import CareFlowAgentExecutor

load_dotenv()
logging.basicConfig(level=logging.ERROR)

DATASET_DIR = os.path.join(os.path.dirname(__file__), "datasets")
REPORT_DIR = os.path.join(os.path.dirname(__file__), "reports")

class MockEventQueue(EventQueue):
    def __init__(self):
        self.events = []
    async def enqueue_event(self, event) -> None:
        self.events.append(event)

async def run_audio_eval():
    os.makedirs(REPORT_DIR, exist_ok=True)
    
    print(f"üéôÔ∏è  CareFlow Pulse - Audio Multimodal Evaluation")
    print(f"‚îÄ" * 60)
    
    audio_files = sorted(glob.glob(os.path.join(DATASET_DIR, "*.wav")))
    if not audio_files:
        print(f"‚ö†Ô∏è  No .wav files found in {DATASET_DIR}")
        return

    executor = CareFlowAgentExecutor(root_agent)

    for audio_path in audio_files:
        file_name = os.path.basename(audio_path)
        print(f"\n‚ñ∂Ô∏è  ANALYZING: {file_name}")
        
        with open(audio_path, "rb") as f:
            audio_b64 = base64.b64encode(f.read()).decode('utf-8')
        # Direct prompt to the agent (bypassing auto-workflow for intelligence testing)
        prompt_text = (
            "Listen to this audio, analyze it carefully and tell us what you understand. "
            "What clinical steps would you take (database, alerts, etc.) "
            "based on the results of your analysis?"
        )
        
        message = Message(
            messageId=str(uuid.uuid4()),
            kind="message",
            role=Role.user,
            parts=[
                Part(root=TextPart(kind="text", text=prompt_text)),
                Part(root=FilePart(kind="file", file=FileWithBytes(bytes=audio_b64, mime_type="audio/wav")))
            ]
        )
        
        context = RequestContext(
            request=MessageSendParams(message=message),
            context_id=f"eval-audio-{file_name}",
            task_id=str(uuid.uuid4())
        )
        mock_queue = MockEventQueue()
        
        print(f"‚åõ Gemini 3 is listening...", end="", flush=True)
        
        agent_report = ""
        agent_reflection = ""
        
        try:
            await executor.execute(context, mock_queue)
            
            for event in mock_queue.events:
                if getattr(event, 'kind', '') == 'status-update' and getattr(event, 'final', False):
                    status = getattr(event, 'status', None)
                    if status and status.message:
                        if status.message.parts:
                            agent_report = "".join([p.root.text for p in status.message.parts if hasattr(p.root, 'text')])
                        metadata = getattr(status.message, 'metadata', {})
                        if metadata:
                            agent_reflection = metadata.get("reflection", "")
        except Exception as e:
            print(f" ‚ùå ERROR: {e}")
            continue

        print(" ‚úÖ")
        
        # Save Report
        report_base_name = os.path.splitext(file_name)[0]
        report_path = os.path.join(REPORT_DIR, f"{report_base_name}-report.md")
        
        with open(report_path, "w", encoding="utf-8") as rf:
            rf.write(f"# CareFlow Pulse - Agent Evaluation Report\n\n")
            rf.write(f"**Audio File:** `{file_name}`\n")
            rf.write(f"**Date:** `{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}`\n\n")
            
            rf.write(f"## üß† Agent Reflection (Thinking Signature)\n")
            rf.write(f"```text\n{agent_reflection if agent_reflection else 'No internal reflection captured.'}\n```\n\n")
            
            rf.write(f"## üìã Final Clinical Assessment\n")
            rf.write(f"{agent_report if agent_report else 'No assessment generated.'}\n\n")
            rf.write(f"---\n*Generated by CareFlow Multimodal Eval v3.4*\n")

        print("‚îÄ" * 60)
        print(f"üìÑ Report saved: reports/{os.path.basename(report_path)}")
        if agent_reflection:
             print(f"üß† Reflection (Snippet): {agent_reflection[:100]}...")
        print("‚îÄ" * 60)

if __name__ == "__main__":
    asyncio.run(run_audio_eval())
