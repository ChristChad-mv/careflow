
# CareFlow Agent Benchmarks

This directory contains benchmarking scripts and performance reports for the CareFlow Pulse ecosystem.

## üõ°Ô∏è Security Latency Benchmark

**Goal:** measure the latency overhead of Google Cloud Model Armor for different security tiers.

### Results (Jan 2026)

| Tier | Description | Protection | Latency Overhead |
| :--- | :--- | :--- | :--- |
| **Tier 1** | Prompt Scanning Only | Prevents Jailbreaks/Injection | **~264 ms** |
| **Tier 2** | Full Bidirectional | Tier 1 + PII Redaction | **~510 ms** (Cumulative) |

### üß† Architectural Decisions

Based on these results, we have implemented a **Tiered Security Model**:

#### 1. CareFlow Caller Agent (Voice) -> **TIER 1 ONLY**

* **Context:** Real-time voice requires <800ms total latency.
* **Impl:** We ENABLE `scan_prompt` but **DISABLE** `sanitize_response`.
* **Reasoning:**
  * The Agent output is generated by trusted Gemini 2.0 Flash.
  * Redaction adds ~250ms which degrades voice UX.
  * We trust the prompt scanner to prevent the agent from being tricked into revealing PII.

#### 2. CareFlow Pulse Agent (Background) -> **TIER 2 (FULL)**

* **Context:** Asynchronous analysis of patient data.
* **Impl:** We ENABLE both `scan_prompt` and `sanitize_response`.
* **Reasoning:**
  * Latency is not critical.
  * Maximum protection for PII/PHI in written reports is required.

---

## üèÉ How to Run

```bash
# Run Security Benchmark
python benchmarks/security/benchmark_tiered_security.py
```
